{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d61e90e-64b4-4c0f-ab49-70a5d7204662",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação \n",
    "\n",
    "Avaliar seu algoritmo the Machine Learning (ML) é parte essencial de qualquer projeto. \n",
    "Existem diversas métricas para avaliar as mais diferences applicações de ML. Para algumas aplicações uma única métrica pode ser o suficente para julgar um modelo, para outras aplicações uma métrica apenas pode não dar ser suficiente para avaliar concretamente seu modelo. \n",
    "\n",
    "Nesta aula vamos ver algumas métricas dos algoritmos de classificação.\n",
    "\n",
    "    - Matriz de confusão\n",
    "    - Acurácia\n",
    "    - Precisão\n",
    "    - Recall\n",
    "    - F1-Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fc6de-da6b-4541-9871-0cbbe25d8623",
   "metadata": {},
   "source": [
    "## Matriz de confusão\n",
    "\n",
    "Uma matriz de confusão é uma tabela que indica os erros e acertos do seu modelo, comparando com o resultado esperado (ou etiquetas/labels). A imagem abaixo demonstra um exemplo de uma matriz de confusão.\n",
    "\n",
    "![image.png](imagens/matrix-de-confusao-1.png)!\n",
    "\n",
    "- Verdadeiros Positivos: classificação correta da classe Positivo;\n",
    "- Falsos Positivos (Erro Tipo I): erro em que o modelo previu a classe Positivo quando o valor real era classe Negativo;\n",
    "- Falsos Negativos (Erro Tipo II): erro em que o modelo previu a classe Negativo quando o valor real era classe Positivo;\n",
    "- Verdadeiros Negativos: classificação correta da classe Negativo.\n",
    "\n",
    "\n",
    "A matriz de confusão oferece uma visão tabular das predições do modelo vs os valores reais esperados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f5314-40ce-4f81-ada1-ef8fd85109de",
   "metadata": {},
   "source": [
    "### Exemplo\n",
    "Digamos que estamos construindo um classificador binário que classifica veiculos militares entre os veículos civis. O nosso cliente nos entregou uma base com 2000 imagens que contém veículos militares e cívis e para cada imagem o nosso cliente nos forneceu o rótulo dizendo se é militar o civil. Os rótulos são 0 se o veículo é militar e 1 se o veículo é civil.\n",
    "\n",
    "Exemplo: \n",
    "<div>\n",
    "<img src=\"imagens/veiculo-militar.png\" width=\"300\"/>\n",
    "<img src=\"imagens/veiculo-civil.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f97376-e48d-448a-8d23-d9375cbafda8",
   "metadata": {},
   "source": [
    "#### Vamos agora treinar um classificador para esse problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebb8a3-face-416b-81b1-484b5d9dd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec842778-31d1-480a-b281-ff20b2f839e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função make_classification gera uma base de dados com base em informações que passamos. \n",
    "X, y = make_classification(n_samples=2000, n_features=10, n_classes=2, random_state=0, weights=(.35, ), n_informative=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ff709-247f-4f91-820f-4e22ab9d2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.DataFrame(X, columns=[f\"Feature_{i}\" for i in range(10)]).join(pd.DataFrame(y, columns=[\"Rótulo\"]))\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b2ea3-0828-4893-9791-5dfb59230dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir a base de trainamento e base de testes\n",
    "X_train, X_test, y_train, y_test = train_test_split(base[base.columns[:-1]], base[\"Rótulo\"], random_state=0, test_size=600, )\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e9f74-2f3b-40e6-9a09-258f32c9272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar um classificador Support Vector Machines\n",
    "clf = SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b162d-0395-4635-8264-82a33382137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd1a34-42cd-4498-9fbc-843ece9c159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "cm = confusion_matrix(y_test, predictions,)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Militar\", \"Civil\"], )\n",
    "disp.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70749057-4cb4-4124-9ac3-ec6e3661711d",
   "metadata": {},
   "source": [
    "- O que a Matriz de Confusão acima nos indica?\n",
    "- Quais são os erros Tipo I e Tipo II?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa340b67-0deb-405e-a570-9926ee2ecc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e3cb4de-1ed4-4be9-b306-608842fd3344",
   "metadata": {},
   "source": [
    "\n",
    "### Derivando as métricas a partir da matriz de confusão\n",
    "\n",
    "\n",
    "A partir desta matriz de confusão conseguimos derivar as principais métricas para avaliar nosso modelo. Veja esse esquema abaixo:\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"imagens/metricas.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "- VP = Verdadeiro Positivo\n",
    "- VN = Verdadeiro Negativo\n",
    "- FP = Falso Positivo\n",
    "- FN = False Negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd4c3d-e578-4600-9707-f02dbb153836",
   "metadata": {},
   "source": [
    "## Acurácia\n",
    "Indica uma performance geral do modelo. Ou seja, dentre todas as predições, quantas o modelo classificou corretamente.\n",
    "\n",
    "- A formula da acurácia é (VP+VN) / VP+VN+FP+FN\n",
    "\n",
    "\n",
    "A palavra acuracidade surgiu a partir da palavra inglesa accuracy, que significa exatidão e rigor.  O termo é definido como exatidão de um valor obtido com relação a um valor tomado como referência. Modelos acurados são aqules cujo a predicão se aproxima do valor correto, ou seja, valor de referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20845ce-b380-4598-97cb-d10792aacc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf434bb-5a38-4da4-9897-692f3191af7f",
   "metadata": {},
   "source": [
    "Acabamos de calcular a acurácia do modelo através da função accuracy_score. Agora vamos validar essa métrica utilizando a fórmula da acurácia e a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba17c9-988b-47f4-b9bd-8ea469d09235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d3de61-2623-4417-afd7-5fc7098b7d6c",
   "metadata": {},
   "source": [
    "## Precisão\n",
    "Indica dentre todas as classificações de classe Positivo que o modelo fez, quantas estão corretas;\n",
    "\n",
    "- A formula da precisão é VP / VP+FP\n",
    "\n",
    "\n",
    "A precisão é utilizada para medir a performance para cada classe. Muito útil para quando estamos lidando com classes desbalanceadas. \n",
    "\n",
    "\n",
    "Olhando esta fórmula, podemos ver que a precisão dá um ênfase maior para os erros por falso positivo. Podemos entender a precisão como sendo a expressão matemática para a pergunta: dos exemplos classificados como positivos, quantos realmente são positivos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba1c49-6b7a-4111-8e2a-13757ad43da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c894ca8-dc47-406d-a6ec-44c2ed23a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, predictions, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c0ff9-f886-4e57-b9d7-7029746eff32",
   "metadata": {},
   "source": [
    "De maneira similar, vamos verificar através da matriz de confusão se os cálculos da acurácia para as classes 0 e 1 (militar oe civil) estão corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9df992-a85f-4b0d-a021-c705ae41d274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daf9ab57-804c-4efa-ade9-a5adb5b5c1cb",
   "metadata": {},
   "source": [
    "## Recall/Revocação/Sensibilidade\n",
    "Indica dentre todas dentre todas as situações de classe Positivo como valor esperado, quantas estão corretas;\n",
    "\n",
    "\n",
    "- A formula da precisão é VP / VP+FN\n",
    "\n",
    "\n",
    "A revocação busca responder a seguinte pergunta: de todos os exemplos que são positivos, quantos foram classificados corretamente como positivos?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d59816-540d-409b-beb6-aa52554e6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a04c2-33fd-4077-88c8-a62fbc5b5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, predictions, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861dae5-da47-40b6-8e05-867d86374a33",
   "metadata": {},
   "source": [
    "Calcule o recall com base na matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4a08e-e1d1-4c50-a4f2-b37aa24170f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82242ea-25be-41f2-ada6-e7034a176afd",
   "metadata": {},
   "source": [
    "## F1-Score\n",
    "\n",
    "É a métrica que leva em consideração tanto a precisão quanto o recall. Ela é definida pela média harmônica entre as duas, como pode ser visto abaixo. \n",
    "\n",
    "- A formula da precisão é F1 = 2 * ((precisão * recall) / (precisao + recall))\n",
    "\n",
    "É uma maneira de visualizar as Métricas de Precisão e Recall em apenas uma métrica. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64535578-90f7-4bf8-9739-c36d42b692e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2c3ee-7ea9-47f7-b2ac-28bdeec06d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(predictions, y_test, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0486cd-0f6f-486c-95bd-c6315295a0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32cc4360-241a-4dc5-a8e7-1e6cc0d4f3cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04df6fd1-a3b6-4de1-8d7f-2f99b38f661e",
   "metadata": {},
   "source": [
    "### Exercicio\n",
    "\n",
    "Vamos analisar a seguinte matriz de confusão. O que podemos dizer deste classificador considerando apenas esta matriz?\n",
    "\n",
    "<div>\n",
    "<img src=\"imagens/matrix-de-confusao-classe-desbalanceada.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee5d72-fc27-466c-8977-514bcdaed327",
   "metadata": {},
   "source": [
    "- Qual é a acurácia deste classificador?\n",
    "- Este é um bom classificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68526c1-015c-4f62-8c82-45e9348989ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeb37920-f472-4419-9f18-fdb00b7a5872",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf645f44-f353-4056-aff9-7f6f6ac5a430",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e610127-0c3d-4bd2-b415-0f0927b57e39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc378dcb-98d4-4e14-a1d4-75f95686ca18",
   "metadata": {},
   "source": [
    "### Exemplo onde a acurácia não é a melhor métrica\n",
    "\n",
    "Uma das maiores desvantagens é que em alguns problemas a acurácia pode ser elevada mas, ainda assim, o modelo pode ter uma performance inadequada. Por exemplo, considere o modelo que classifica exames de câncer entre positivo ou negativo para a doença, e em nosso conjunto de dados temos 1000 exemplos, sendo 998 de pacientes sem câncer e 2 de pacientes com câncer. \n",
    "Caso nosso modelo seja ingênuo e sempre classifique todos os exemplos com negativo (sem câncer), ele ainda obteria uma acurácia de 99%. \n",
    "\n",
    "O que parece uma excelente métrica, mas na verdade não estamos avaliando nosso modelo de forma adequada. Para melhor avaliar modelos que lidam com conjuntos de dados desbalanceados como este, devemos utilizar as outras métrica vistas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a562b2-575c-42e1-bbd4-d7e45d1456fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4f10586-a27b-4e64-b91b-033de09e82da",
   "metadata": {},
   "source": [
    "Vamos criar uma base de dados para exemplificar o problema acima. \n",
    "\n",
    "- Será uma base com 10.000 pacientes onde apenas 5% apresenta câncer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f21d7f-541e-4e8f-8b4e-6ca098398e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=50, n_classes=2, random_state=0, weights=(.05, .95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22b089-02e7-48eb-8fa2-40e2e3801818",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=1000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf32c5-75e0-4418-bfae-58fe30af8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test == 1), sum(y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c157c8-f499-4bdb-a288-5d9f6e4959fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar um classificador Support Vector Machines\n",
    "clf = SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485eb18-0e4f-492f-a80e-b394bc925581",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8001d-38c8-46f9-b0c3-5eea1d9b501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a530794-e7b7-47d3-ae97-06c221c584e8",
   "metadata": {},
   "source": [
    "Agora calcule as métricas de acurácia, precisão, recall e F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a2cca-1ed1-4297-ae57-48853d1b9c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f906c3-1f42-4038-9bd2-838b8ebcf32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29516b2-2378-4922-8db2-d822f6599176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a9312-e5a3-4707-bbe4-40f17edf7743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7b837-6ad6-4967-b5b3-d57bcabd976c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48348df6-a994-4e7a-a947-ff7527f26bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
